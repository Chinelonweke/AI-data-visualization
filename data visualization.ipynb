{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import io\n",
    "import contextlib\n",
    "import warnings\n",
    "from typing import Optional, List, Any, Tuple\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt  # Import Matplotlib for visualizations\n",
    "import seaborn as sns  # Import Seaborn for better plotting\n",
    "import streamlit as st\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Regular Expression for Extracting Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This regular expression will help you extract Python code blocks from the response of the language model.\n",
    "\n",
    "pattern = re.compile(r\"```python\\n(.*?)\\n```\", re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Function to Execute Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will execute Python code provided by the LLM. It will also handle capturing\n",
    "#  and displaying Matplotlib plots generated during the execution.\n",
    "\n",
    "def code_interpret(code: str) -> Optional[List[Any]]:\n",
    "    with st.spinner('Executing code...'):  # Show loading spinner during execution\n",
    "        stdout_capture = io.StringIO()  # Capture standard output\n",
    "        stderr_capture = io.StringIO()  # Capture standard error\n",
    "\n",
    "        # Redirect stdout and stderr to capture output and errors\n",
    "        with contextlib.redirect_stdout(stdout_capture), contextlib.redirect_stderr(stderr_capture):\n",
    "            try:\n",
    "                exec(code)  # Execute the code provided by LLM\n",
    "            except Exception as e:  # Catch any exceptions during code execution\n",
    "                stderr_capture.write(str(e))  # Write the error message\n",
    "\n",
    "        # Check if there are any errors in stderr\n",
    "        if stderr_capture.getvalue():\n",
    "            print(\"[Code Interpreter Warnings/Errors]\", file=sys.stderr)\n",
    "            print(stderr_capture.getvalue(), file=sys.stderr)\n",
    "\n",
    "        # If there is any output in stdout, print it\n",
    "        if stdout_capture.getvalue():\n",
    "            print(\"[Code Interpreter Output]\", file=sys.stdout)\n",
    "            print(stdout_capture.getvalue(), file=sys.stdout)\n",
    "\n",
    "        # Capture and return the generated plots\n",
    "        if plt.get_fignums():  # If there are any open figures (plots)\n",
    "            fig = plt.gcf()  # Get the current figure\n",
    "            img_buf = BytesIO()\n",
    "            fig.savefig(img_buf, format='png')  # Save the figure to a buffer\n",
    "            img_buf.seek(0)\n",
    "            img = Image.open(img_buf)\n",
    "            st.image(img)  # Display the plot in Streamlit\n",
    "            plt.close(fig)  # Close the figure to free up memory\n",
    "\n",
    "        return stdout_capture.getvalue()  # Return any textual output from code execution\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Match Python Code Blocks in LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts Python code from the model's response if it contains any.\n",
    "\n",
    "def match_code_blocks(llm_response: str) -> str:\n",
    "    match = pattern.search(llm_response)\n",
    "    if match:\n",
    "        code = match.group(1)\n",
    "        return code\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Interact with Hugging Face LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sends the user's query to the LLM and retrieves the response. \n",
    "# It also executes any Python code generated by the model.\n",
    "\n",
    "def chat_with_llm(user_message: str, dataset_path: str) -> Tuple[Optional[List[Any]], str]:\n",
    "    # Load model and tokenizer (open-source model)\n",
    "    model_name = \"meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo\"  # You can change this model to another open-source one\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Construct system prompt with dataset path\n",
    "    system_prompt = f\"\"\"You're a Python data scientist and data visualization expert. You are given a dataset at path '{dataset_path}' and also the user's query.\n",
    "    You need to analyze the dataset and answer the user's query with a response and you run Python code to solve them.\n",
    "    IMPORTANT: Always use the dataset path variable '{dataset_path}' in your code when reading the CSV file.\"\"\"\n",
    "\n",
    "    # Encode the prompt and user message\n",
    "    inputs = tokenizer.encode(system_prompt + \"\\n\" + user_message, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate response using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs, max_length=1024, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    response_message = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    python_code = match_code_blocks(response_message)\n",
    "    \n",
    "    if python_code:\n",
    "        code_results = code_interpret(python_code)\n",
    "        return code_results, response_message\n",
    "    else:\n",
    "        st.warning(f\"Failed to match any Python code in model's response\")\n",
    "        return None, response_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Handle File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function handles the uploading of the dataset. \n",
    "# It stores the dataset locally and returns the dataset's file path.\n",
    "\n",
    "def upload_dataset(uploaded_file) -> str:\n",
    "    dataset_path = f\"./{uploaded_file.name}\"\n",
    "    \n",
    "    try:\n",
    "        with open(dataset_path, 'wb') as f:\n",
    "            f.write(uploaded_file.getbuffer())\n",
    "        return dataset_path\n",
    "    except Exception as error:\n",
    "        st.error(f\"Error during file upload: {error}\")\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Streamlit Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 00:55:40.285 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.396 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Chinelo\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-01-23 00:55:40.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.401 Session state does not function when running a script without `streamlit run`\n",
      "2025-01-23 00:55:40.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.408 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.412 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.413 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.415 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.417 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.419 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.421 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.424 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.425 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.425 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.426 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.427 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.428 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.429 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.430 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.431 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.432 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.433 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.434 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.435 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.436 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.437 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.437 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.438 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.439 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.440 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.441 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.443 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.444 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.445 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.446 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.448 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-01-23 00:55:40.450 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# This is the main function of your Streamlit app, \n",
    "# where you handle file uploads, query input, and visualizations.\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from e2b_code_interpreter import Sandbox  # Assuming this is a custom library for sandboxed code execution\n",
    "\n",
    "def upload_dataset(uploaded_file):\n",
    "    \"\"\"Function to upload dataset and return the dataset path.\"\"\"\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    # Save the file temporarily for later use (this might depend on your platform)\n",
    "    dataset_path = \"path/to/uploaded/dataset.csv\"\n",
    "    df.to_csv(dataset_path, index=False)\n",
    "    return dataset_path\n",
    "\n",
    "def chat_with_llm(query, dataset_path):\n",
    "    \"\"\"Function to interact with the language model and process the query.\"\"\"\n",
    "    # This is a placeholder for the actual interaction with the LLM (Language Model)\n",
    "    # It should return the generated code to analyze the dataset and its response\n",
    "    code_results = \"Analysis Result Placeholder\"\n",
    "    llm_response = \"AI Response Placeholder\"\n",
    "    return code_results, llm_response\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main Streamlit application.\"\"\"\n",
    "    # Step 1: Display title and introduction\n",
    "    st.title(\"📊 AI Data Visualization Agent\")\n",
    "    st.write(\"Upload your dataset and ask questions about it!\")\n",
    "\n",
    "    # Step 2: Initialize session state variables for API keys and model\n",
    "    if 'together_api_key' not in st.session_state:\n",
    "        st.session_state.together_api_key = ''\n",
    "    if 'e2b_api_key' not in st.session_state:\n",
    "        st.session_state.e2b_api_key = ''\n",
    "    if 'model_name' not in st.session_state:\n",
    "        st.session_state.model_name = ''\n",
    "\n",
    "    # Step 3: Sidebar for API Key input and Model Configuration\n",
    "    with st.sidebar:\n",
    "        st.header(\"API Keys and Model Configuration\")\n",
    "        st.session_state.together_api_key = st.sidebar.text_input(\"Together AI API Key\", type=\"password\")\n",
    "        st.sidebar.info(\"💡 Everyone gets a free $1 credit by Together AI - AI Acceleration Cloud platform\")\n",
    "        st.sidebar.markdown(\"[Get Together AI API Key](https://api.together.ai/signin)\")\n",
    "        \n",
    "        st.session_state.e2b_api_key = st.sidebar.text_input(\"Enter E2B API Key\", type=\"password\")\n",
    "        st.sidebar.markdown(\"[Get E2B API Key](https://e2b.dev/docs/legacy/getting-started/api-key)\")\n",
    "        \n",
    "        # Add model selection dropdown\n",
    "        model_options = {\n",
    "            \"Meta-Llama 3.1 405B\": \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "            \"DeepSeek V3\": \"deepseek-ai/DeepSeek-V3\",\n",
    "            \"Qwen 2.5 7B\": \"Qwen/Qwen2.5-7B-Instruct-Turbo\",\n",
    "            \"Meta-Llama 3.3 70B\": \"meta-llama/Llama-3.3-70B-Instruct-Turbo\"\n",
    "        }\n",
    "        st.session_state.model_name = st.selectbox(\n",
    "            \"Select Model\",\n",
    "            options=list(model_options.keys()),\n",
    "            index=0  # Default to first option\n",
    "        )\n",
    "        st.session_state.model_name = model_options[st.session_state.model_name]\n",
    "\n",
    "    # Step 4: Upload CSV file\n",
    "    uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Display dataset with toggle for preview or full dataset\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        st.write(\"Dataset:\")\n",
    "        show_full = st.checkbox(\"Show full dataset\")\n",
    "        if show_full:\n",
    "            st.dataframe(df)\n",
    "        else:\n",
    "            st.write(\"Preview (first 5 rows):\")\n",
    "            st.dataframe(df.head())\n",
    "        \n",
    "        # Step 5: User input for query\n",
    "        query = st.text_area(\"What would you like to know about your data?\",\n",
    "                             \"Can you compare the average cost for two people between different categories?\")\n",
    "        \n",
    "        # Step 6: Analyze button and results display\n",
    "        if st.button(\"Analyze\"):\n",
    "            if not st.session_state.together_api_key or not st.session_state.e2b_api_key:\n",
    "                st.error(\"Please enter both API keys in the sidebar.\")\n",
    "            else:\n",
    "                with Sandbox(api_key=st.session_state.e2b_api_key) as code_interpreter:\n",
    "                    # Upload the dataset to the sandbox (assuming the sandbox requires a path)\n",
    "                    dataset_path = upload_dataset(uploaded_file)\n",
    "                    \n",
    "                    # Pass dataset_path to chat_with_llm for code generation\n",
    "                    code_results, llm_response = chat_with_llm(query, dataset_path)\n",
    "                    \n",
    "                    # Display AI's text response\n",
    "                    st.write(\"AI Response:\")\n",
    "                    st.write(llm_response)\n",
    "                    \n",
    "                    # Handle and display results\n",
    "                    if code_results:\n",
    "                        for result in code_results:\n",
    "                            if hasattr(result, 'png') and result.png:  # Check if PNG data is available\n",
    "                                # Decode the base64-encoded PNG data and display the image\n",
    "                                png_data = base64.b64decode(result.png)\n",
    "                                image = Image.open(BytesIO(png_data))\n",
    "                                st.image(image, caption=\"Generated Visualization\", use_container_width=False)\n",
    "                            elif hasattr(result, 'figure'):  # For matplotlib figures\n",
    "                                fig = result.figure  # Extract matplotlib figure\n",
    "                                st.pyplot(fig)  # Display using st.pyplot\n",
    "                            elif hasattr(result, 'show'):  # For plotly figures\n",
    "                                st.plotly_chart(result)\n",
    "                            elif isinstance(result, (pd.DataFrame, pd.Series)):\n",
    "                                st.dataframe(result)\n",
    "                            else:\n",
    "                                st.write(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
